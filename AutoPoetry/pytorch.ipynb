{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 自动写诗"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义 Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare\n",
    "import torch\n",
    "import visdom\n",
    "import tqdm\n",
    "import ipdb\n",
    "import numpy as np\n",
    "import torchvision as tv\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch import nn, optim\n",
    "from torchnet import meter\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "# Config\n",
    "\n",
    "class Config(object):\n",
    "\n",
    "    lr = 1e-3\n",
    "\n",
    "    epoch = 20\n",
    "    batch_size = 128\n",
    "    \n",
    "    embedding_dim = 128\n",
    "    hidden_dim = 256\n",
    "\n",
    "    max_gen_len = 200\n",
    "\n",
    "opt = Config()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义 Visualizer 可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import visdom\n",
    "import torch as t\n",
    "import time\n",
    "import torchvision as tv\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class Visualizer():\n",
    "    \"\"\"\n",
    "    封装了visdom的基本操作，但是你仍然可以通过`self.vis.function`\n",
    "    调用原生的visdom接口\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, env='default', **kwargs):\n",
    "        import visdom\n",
    "        self.vis = visdom.Visdom(env=env, use_incoming_socket=False, **kwargs)\n",
    "\n",
    "        # 画的第几个数，相当于横座标\n",
    "        # 保存（’loss',23） 即loss的第23个点\n",
    "        self.index = {}\n",
    "        self.log_text = ''\n",
    "\n",
    "    def reinit(self, env='default', **kwargs):\n",
    "        \"\"\"\n",
    "        修改visdom的配置\n",
    "        \"\"\"\n",
    "        self.vis = visdom.Visdom(env=env,use_incoming_socket=False, **kwargs)\n",
    "        return self\n",
    "\n",
    "    def plot_many(self, d):\n",
    "        \"\"\"\n",
    "        一次plot多个\n",
    "        @params d: dict (name,value) i.e. ('loss',0.11)\n",
    "        \"\"\"\n",
    "        for k, v in d.items():\n",
    "            self.plot(k, v)\n",
    "\n",
    "    def img_many(self, d):\n",
    "        for k, v in d.items():\n",
    "            self.img(k, v)\n",
    "\n",
    "    def plot(self, name, y):\n",
    "        \"\"\"\n",
    "        self.plot('loss',1.00)\n",
    "        \"\"\"\n",
    "        x = self.index.get(name, 0)\n",
    "        self.vis.line(Y=np.array([y]), X=np.array([x]),\n",
    "                      win=name,\n",
    "                      opts=dict(title=name),\n",
    "                      update=None if x == 0 else 'append'\n",
    "                      )\n",
    "        self.index[name] = x + 1\n",
    "\n",
    "    def img(self, name, img_):\n",
    "        \"\"\"\n",
    "        self.img('input_img',t.Tensor(64,64))\n",
    "        \"\"\"\n",
    "\n",
    "        if len(img_.size()) < 3:\n",
    "            img_ = img_.cpu().unsqueeze(0)\n",
    "        self.vis.image(img_.cpu(),\n",
    "                       win=name,\n",
    "                       opts=dict(title=name)\n",
    "                       )\n",
    "\n",
    "    def img_grid_many(self, d):\n",
    "        for k, v in d.items():\n",
    "            self.img_grid(k, v)\n",
    "\n",
    "    def img_grid(self, name, input_3d):\n",
    "        \"\"\"\n",
    "        一个batch的图片转成一个网格图，i.e. input（36，64，64）\n",
    "        会变成 6*6 的网格图，每个格子大小64*64\n",
    "        \"\"\"\n",
    "        self.img(name, tv.utils.make_grid(\n",
    "            input_3d.cpu()[0].unsqueeze(1).clamp(max=1, min=0)))\n",
    "\n",
    "    def log(self, info, win='log_text'):\n",
    "        \"\"\"\n",
    "        self.log({'loss':1,'lr':0.0001})\n",
    "        \"\"\"\n",
    "\n",
    "        self.log_text += ('[{time}] {info} <br>'.format(\n",
    "            time=time.strftime('%m%d_%H%M%S'),\n",
    "            info=info))\n",
    "        self.vis.text(self.log_text, win=win)\n",
    "\n",
    "    def __getattr__(self, name):\n",
    "        return getattr(self.vis, name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义模型 PoetryModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class PoetryModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim):\n",
    "        super(PoetryModel, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(input_size=embedding_dim, hidden_size=self.hidden_dim, num_layers=2)\n",
    "        self.linear = nn.Linear(self.hidden_dim, vocab_size)\n",
    "\n",
    "    def forward(self, input, hidden=None):\n",
    "        seq_len, batch_size = input.size()\n",
    "        if hidden is None:\n",
    "            h_0 = input.data.new(2, batch_size, self.hidden_dim).fill_(0).float()\n",
    "            c_0 = input.data.new(2, batch_size, self.hidden_dim).fill_(0).float()\n",
    "        else:\n",
    "            h_0, c_0 = hidden\n",
    "            \n",
    "        embeds = self.embeddings(input)\n",
    "\n",
    "        output, hidden = self.lstm(embeds, (h_0, c_0))\n",
    "\n",
    "        output = self.linear(output.view(seq_len * batch_size, -1))\n",
    "        \n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareData():\n",
    "    datas = np.load(\"data/tang.npz\", allow_pickle=True)\n",
    "    print(datas)\n",
    "    data = datas['data']\n",
    "    ix2word = datas['ix2word'].item()\n",
    "    word2ix = datas['word2ix'].item()\n",
    "    data = torch.from_numpy(data)\n",
    "    dataloader = DataLoader(data,\n",
    "                            batch_size=opt.batch_size,\n",
    "                            shuffle=True,\n",
    "                            num_workers=2)\n",
    "    return dataloader, ix2word, word2ix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "<numpy.lib.npyio.NpzFile object at 0x7ff6dc5d63a0>\n</s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s><START>紫髯青眼代天才，韩白孙吴稍可陪。祗见赤心尧日下，岂知真气梵天来。听经瑞雪时时落，登塔天花步步开。尽祝庄椿同壽考，人间岁月岂能催。<EOP>\n"
    }
   ],
   "source": [
    "dataloader, ix2word, _ = prepareData()\n",
    "for batch_size, data in enumerate(dataloader):\n",
    "    poem1 = data[0]\n",
    "    poem = \"\"\n",
    "    for i in poem1:\n",
    "        poem += ix2word[int(i)]\n",
    "    print(poem)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 生成诗句"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(model, start_words, ix2word, word2ix, prefix_words = None):\n",
    "    results = list(start_words)\n",
    "    start_words_len = len(start_words)\n",
    "\n",
    "    # 第一个词语是<START>\n",
    "    input = t.Tensor([word2ix['<START>']]).view(1, 1).long().cuda()\n",
    "    hidden = None\n",
    "\n",
    "    if prefix_words != None:\n",
    "        for word in prefix_words:\n",
    "            output, hidden = model(input, hidden)\n",
    "            input = input.data.new([word2ix[word]]).view(1, 1)\n",
    "\n",
    "    for i in range(opt.max_gen_len):\n",
    "        output, hidden = model(input, hidden)\n",
    "        # 如果在给定的句首中，input为句首中的下一个字\n",
    "        if i < start_words_len:\n",
    "            w = results[i]\n",
    "            input = input.data.new([word2ix[w]]).view(1, 1)\n",
    "        # 否则将output作为下一个input进行\n",
    "        else:\n",
    "            top_index = output.data[0].topk(1)[1][0].item()\n",
    "            w = ix2word[top_index]\n",
    "            results.append(w)\n",
    "            input = input.data.new([top_index]).view(1, 1)\n",
    "        if w == '<EOP>':\n",
    "            del results[-1]\n",
    "            break\n",
    "    return results\n",
    "\n",
    "# def generate(model, start_words, ix2word, word2ix):\n",
    "#     results = list(start_words)\n",
    "#     start_words_len = len(start_words)\n",
    "#     # 第一个词语是<START>\n",
    "#     input = t.Tensor([word2ix['<START>']]).view(1, 1).long().cuda()\n",
    "#     hidden = None\n",
    "#     model.eval().cuda()\n",
    "#     with torch.no_grad():\n",
    "#         for i in range(Config.max_gen_len):\n",
    "#             output, hidden = model(input, hidden)\n",
    "# \t\t    # 如果在给定的句首中，input为句首中的下一个字\n",
    "#             if i < start_words_len:\n",
    "#                 w = results[i]\n",
    "#                 input = input.data.new([word2ix[w]]).view(1, 1)\n",
    "#            # 否则将output作为下一个input进行\n",
    "#             else:\n",
    "#                 top_index = output.data[0].topk(1)[1][0].item()\n",
    "#                 w = ix2word[top_index]\n",
    "#                 results.append(w)\n",
    "#                 input = input.data.new([top_index]).view(1, 1)\n",
    "#             if w == '<EOP>':\n",
    "#                 del results[-1]\n",
    "#                 break\n",
    "#         return results\n",
    "\n",
    "\n",
    "def gen_acrostic(model, start_words, ix2word, word2ix, prefix_words=None):\n",
    "\n",
    "    results = []\n",
    "    start_word_len = len(start_words)\n",
    "    input = (t.Tensor([word2ix['<START>']]).view(1, 1).long()).cuda()\n",
    "    hidden = None\n",
    "\n",
    "    index = 0  # 用来指示已经生成了多少句藏头诗\n",
    "    # 上一个词\n",
    "    pre_word = '<START>'\n",
    "\n",
    "    if prefix_words:\n",
    "        for word in prefix_words:\n",
    "            output, hidden = model(input, hidden)\n",
    "            input = (input.data.new([word2ix[word]])).view(1, 1)\n",
    "\n",
    "    for i in range(opt.max_gen_len):\n",
    "        output, hidden = model(input, hidden)\n",
    "        top_index = output.data[0].topk(1)[1][0].item()\n",
    "        w = ix2word[top_index]\n",
    "\n",
    "        if (pre_word in {u'。', u'！', '<START>'}):\n",
    "            # 如果遇到句号，藏头的词送进去生成\n",
    "\n",
    "            if index == start_word_len:\n",
    "                # 如果生成的诗歌已经包含全部藏头的词，则结束\n",
    "                break\n",
    "            else:\n",
    "                # 把藏头的词作为输入送入模型\n",
    "                w = start_words[index]\n",
    "                index += 1\n",
    "                input = (input.data.new([word2ix[w]])).view(1, 1)\n",
    "        else:\n",
    "            # 否则的话，把上一次预测是词作为下一个词输入\n",
    "            input = (input.data.new([word2ix[w]])).view(1, 1)\n",
    "        results.append(w)\n",
    "        pre_word = w\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, word2ix):\n",
    "    vis = Visualizer(env=\"autoPoem\")\n",
    "    # 定义模型\n",
    "    model = PoetryModel(len(word2ix),\n",
    "                      embedding_dim=opt.embedding_dim,\n",
    "                      hidden_dim=opt.hidden_dim)\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=opt.lr)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    model.cuda()\n",
    "    criterion.cuda()\n",
    "\n",
    "    loss_meter = meter.AverageValueMeter()\n",
    "\n",
    "    for epoch in range(opt.epoch):\n",
    "        loss_meter.reset()\n",
    "\n",
    "        for i, data in tqdm.tqdm(enumerate(dataloader)):\n",
    "            model.train()\n",
    "            data = data.long().transpose(1,0).contiguous().cuda()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            input, target = data[:-1,:], Variable(data[1:,:])\n",
    "\n",
    "            output,_ = model(input)\n",
    "            loss = criterion(output, target.view(-1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            loss_meter.add(loss.item())\n",
    "\n",
    "            if (1+i) % 100 == 0:\n",
    "                vis.plot('loss', loss_meter.value()[0])\n",
    "                poetrys = [[ix2word[_word] for _word in data[:, _iii].tolist()]\n",
    "                           for _iii in range(data.shape[1])][:16]\n",
    "\n",
    "                vis.text('</br>'.join([''.join(poetry) for poetry in poetrys]),win = u'origin_poem')\n",
    "\n",
    "                gen_poetries = []\n",
    "\n",
    "                for word in list(u'深度学习真的有趣'):\n",
    "                    gen_poetry = ''.join(generate(model, word, ix2word, word2ix))\n",
    "                    gen_poetries.append(gen_poetry)\n",
    "                vis.text('</br>'.join([''.join(poetry) for poetry in gen_poetries]), win=u'gen_poem')\n",
    "\n",
    "        t.save(model.state_dict(), 'model/pytorch/model_epoch_%s.pth' %epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "<numpy.lib.npyio.NpzFile object at 0x7ff6dc5bb0a0>\nSetting up a new session...\nWithout the incoming socket you cannot receive events from the server or register event handlers to your Visdom client.\n450it [00:27, 16.23it/s]\n450it [00:27, 16.32it/s]\n450it [00:27, 16.28it/s]\n450it [00:27, 16.11it/s]\n450it [00:28, 16.06it/s]\n450it [00:28, 15.62it/s]\n450it [00:28, 15.52it/s]\n450it [00:28, 15.55it/s]\n450it [00:28, 15.75it/s]\n450it [00:28, 15.52it/s]\n450it [00:29, 15.28it/s]\n450it [00:29, 15.15it/s]\n450it [00:30, 14.72it/s]\n450it [00:31, 14.34it/s]\n450it [00:30, 14.63it/s]\n450it [00:30, 14.69it/s]\n450it [00:30, 14.67it/s]\n450it [00:30, 14.74it/s]\n450it [00:30, 14.59it/s]\n450it [00:31, 14.51it/s]\n"
    }
   ],
   "source": [
    "dataloader, ix2word, word2ix = prepareData()\n",
    "train(dataloader, word2ix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 生成诗歌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "<numpy.lib.npyio.NpzFile object at 0x7ff668bc4ee0>\n枯藤老树昏鸦，一片红莲叶下枝。一枝一朵红叶绿，一朵红霞红粉垂。一朵红霞映碧落，一朵红莲映春色。一枝红豔豔红妆，一朵红妆红粉鲜。红粉红妆不可见，红妆粉黛如相看。不知不觉春风起，不觉春风吹落花。不觉春风吹不得，不知何处是春时。不知此日无人识，不觉春风不可知。自有春风吹不得，不知何处是何时？花间不得无人见，花落春来不可知。自有春风吹不得，不知何处是何时？花间不见无人识，花落春来不可知。自有春风吹不得，不\n"
    }
   ],
   "source": [
    "# Load model \n",
    "dataloader, ix2word, word2ix = prepareData()\n",
    "model = PoetryModel(len(word2ix),\n",
    "                      embedding_dim=opt.embedding_dim,\n",
    "                      hidden_dim=opt.hidden_dim)\n",
    "\n",
    "map_location = lambda s, l: s\n",
    "state_dict = torch.load('model/pytorch/model_epoch_19.pth', map_location=map_location)\n",
    "\n",
    "model.load_state_dict(state_dict)\n",
    "model.cuda()\n",
    "\n",
    "start_words = u'枯藤老树昏鸦'\n",
    "prefix_words = u'枯藤老树昏鸦小桥流水人家'\n",
    "\n",
    "\n",
    "result = generate(model, start_words, ix2word, word2ix, prefix_words)\n",
    "print(''.join(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![avatar](data/1.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![avatar](data/2.png)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}